{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3559db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for request.\n",
      "HTTP Status code: 204\n",
      "Detailed response of server:\n",
      "\n",
      " for 249\n",
      "No data available for request.\n",
      "HTTP Status code: 204\n",
      "Detailed response of server:\n",
      "\n",
      " for 210\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_169286/2419526890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    277\u001b[0m                                           \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mista\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                                           \u001b[0mstarttime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                                           endtime=s2)\n\u001b[0m\u001b[1;32m    280\u001b[0m                 \u001b[0mt1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/envs/noisepy/lib/python3.7/site-packages/obspy/clients/fdsn/client.py\u001b[0m in \u001b[0;36mget_waveforms\u001b[0;34m(self, network, station, location, channel, starttime, endtime, quality, minimumlength, longestonly, filename, attach_response, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;31m# Gzip not worth it for MiniSEED and most likely disabled for this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;31m# route in any case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mdata_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gzip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m         \u001b[0mdata_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/envs/noisepy/lib/python3.7/site-packages/obspy/clients/fdsn/client.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(self, url, return_string, data, use_gzip, content_type)\u001b[0m\n\u001b[1;32m   1422\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url_opener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m             timeout=self.timeout, use_gzip=use_gzip)\n\u001b[0m\u001b[1;32m   1425\u001b[0m         \u001b[0mraise_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/envs/noisepy/lib/python3.7/site-packages/obspy/clients/fdsn/client.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, opener, timeout, headers, debug, return_string, data, use_gzip)\u001b[0m\n\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_string\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1866\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1867\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/envs/noisepy/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readall_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/envs/noisepy/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_readall_chunked\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/envs/noisepy/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/envs/noisepy/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import obspy\n",
    "import pyasdf\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.insert(1,'/home/bxh220006/software/JnoisePy/src')\n",
    "import noise_module\n",
    "from mpi4py import MPI\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "'''\n",
    "This script:\n",
    "    1) downloads sesimic data located in a broad region defined by user or using a pre-compiled station list;\n",
    "    2) cleans up raw traces by removing gaps, instrumental response, downsampling and trimming to a day length;\n",
    "    3) saves data into ASDF format (see Krischer et al., 2016 for more details on the data structure);\n",
    "    4) parallelize the downloading processes with MPI.\n",
    "    5) avoids downloading data for stations that already have 1 or 3 channels\n",
    "\n",
    "Authors: Chengxin Jiang (chengxin_jiang@fas.harvard.edu) \n",
    "         Marine Denolle (mdenolle@fas.harvard.edu) \n",
    "\n",
    "NOTE: \n",
    "    0. MOST occasions you just need to change parameters followed with detailed explanations to run the script. \n",
    "    1. to avoid segmentation fault later in cross-correlation calculations due to too large data in memory,\n",
    "    a rough estimation of the memory needs is made in the beginning of the code. you can reduce the value of\n",
    "    inc_hours if memory on your machine is not enough to load proposed (x) hours of noise data all at once;\n",
    "    2. if choose to download stations from an existing CSV files, stations with the same name but different\n",
    "    channel is regarded as different stations (same format as those generated by the S0A);\n",
    "    3. for unknow reasons, including station location code during feteching process sometime result in no-data.\n",
    "    Therefore, we recommend setting location code to \"*\" in the request setting (L105 & 134) when it is confirmed\n",
    "    manually by the users that no stations with same name but different location codes occurs.\n",
    "\n",
    "Enjoy the NoisePy journey! \n",
    "'''\n",
    "\n",
    "#########################################################\n",
    "################ PARAMETER SECTION ######################\n",
    "#########################################################\n",
    "tt0=time.time()\n",
    "\n",
    "# paths and filenames\n",
    "rootpath = './'                     # roothpath for the project\n",
    "direc  = os.path.join(rootpath,'RAW_DATA')                      # where to store the downloaded data\n",
    "dlist  = os.path.join(direc,'station.txt')                      # CSV file for station location info\n",
    "\n",
    "# download parameters\n",
    "client    = Client('IRISPH5')                                     # client/data center. see https://docs.obspy.org/packages/obspy.clients.fdsn.html for a list\n",
    "down_list = False                                               # download stations from a pre-compiled list or not\n",
    "flag      = False                                               # print progress when running the script; recommend to use it at the begining\n",
    "samp_freq = 4                                                  # targeted sampling rate at X samples per seconds \n",
    "rm_resp   = 'inv'                                                # select 'no' to not remove response and use 'inv','spectrum','RESP', or 'polozeros' to remove response\n",
    "respdir   = os.path.join(rootpath,'resp')                       # directory where resp files are located (required if rm_resp is neither 'no' nor 'inv')\n",
    "freqmin   = 0.05                                                # pre filtering frequency bandwidth\n",
    "freqmax   = 1.0                                                 # note this cannot exceed Nquist freq                         \n",
    "\n",
    "# targeted region/station information: only needed when down_list is False\n",
    "lamin,lamax,lomin,lomax = 34.0834,34.156,-118.2134,-117.2692               # regional box: min lat, min lon, max lat, max lon (-114.0)\n",
    "chan_list = [\"DPZ\"]                                             # channel if down_list=false (format like \"HN?\" not work here)\n",
    "net_list  = [\"6J\"]                                              # network list \n",
    "sta_list  = [\"1007\",\"1259\"]                                               # station (using a station list is way either compared to specifying stations one by one)\n",
    "start_date = [\"2019_11_10_0_0_0\"]                               # start date of download\n",
    "end_date   = [\"2019_12_11_0_0_0\"]                               # end date of download\n",
    "inc_hours  = 24                                                 # length of data for each request (in hour)\n",
    "ncomp      = len(chan_list)\n",
    "\n",
    "# get rough estimate of memory needs to ensure it now below up in S1\n",
    "cc_len    = 1800                                                # basic unit of data length for fft (s)\n",
    "step      = 450                                                 # overlapping between each cc_len (s)\n",
    "MAX_MEM   = 5.0                                                 # maximum memory allowed per core in GB\n",
    "\n",
    "##################################################\n",
    "# we expect no parameters need to be changed below\n",
    "\n",
    "# time tags\n",
    "starttime = obspy.UTCDateTime(start_date[0])       \n",
    "endtime   = obspy.UTCDateTime(end_date[0])\n",
    "if flag:\n",
    "    print('station.list selected [%s] for data from %s to %s with %sh interval'%(down_list,starttime,endtime,inc_hours))\n",
    "\n",
    "# assemble parameters used for pre-processing\n",
    "prepro_para = {'rm_resp':rm_resp,\n",
    "               'respdir':respdir,\n",
    "               'freqmin':freqmin,\n",
    "               'freqmax':freqmax,\n",
    "               'samp_freq':samp_freq,\n",
    "               'start_date':start_date,\n",
    "               'end_date':end_date,\n",
    "               'inc_hours':inc_hours,\n",
    "               'cc_len':cc_len,\n",
    "               'step':step,\n",
    "               'MAX_MEM':MAX_MEM,\n",
    "               'lamin':lamin,\n",
    "               'lamax':lamax,\n",
    "               'lomin':lomin,\n",
    "               'lomax':lomax,\n",
    "               'ncomp':ncomp}\n",
    "metadata = os.path.join(direc,'download_info.txt') \n",
    "\n",
    "# prepare station info (existing station list vs. fetching from client)\n",
    "if down_list:\n",
    "    if not os.path.isfile(dlist):\n",
    "        raise IOError('file %s not exist! double check!' % dlist)\n",
    "\n",
    "    # read station info from list\n",
    "    locs = pd.read_csv(dlist)                   \n",
    "    nsta = len(locs)\n",
    "    chan = list(locs.iloc[:]['channel'])\n",
    "    net  = list(locs.iloc[:]['network'])\n",
    "    sta  = list(locs.iloc[:]['station'])\n",
    "    lat  = list(locs.iloc[:]['latitude'])\n",
    "    lon  = list(locs.iloc[:]['longitude'])\n",
    "\n",
    "    # location info: useful for some occasion\n",
    "    try:\n",
    "        location = list(locs.iloc[:]['location'])\n",
    "    except Exception as e:\n",
    "        location = ['*']*nsta\n",
    "\n",
    "else:\n",
    "\n",
    "    # calculate the total number of channels to download\n",
    "    sta=[];net=[];chan=[];location=[];lon=[];lat=[];elev=[]\n",
    "    nsta=0\n",
    "\n",
    "    # loop through specified network, station and channel lists\n",
    "    for inet in net_list:\n",
    "        for ista in sta_list:\n",
    "            for ichan in chan_list:\n",
    "                # gather station info\n",
    "                try:\n",
    "                    inv = client.get_stations(network=inet,\n",
    "                                              station=ista,\n",
    "                                              channel=ichan,\n",
    "                                              location='*',\n",
    "                                              starttime=starttime,\n",
    "                                              endtime=endtime,\n",
    "                                              minlatitude=lamin,\n",
    "                                              maxlatitude=lamax, \n",
    "                                              minlongitude=lomin, \n",
    "                                              maxlongitude=lomax,\n",
    "                                              level='response')\n",
    "                except Exception as e:\n",
    "                    print('Abort at L126 in S0A due to '+str(e))\n",
    "                    sys.exit()\n",
    "\n",
    "                for K in inv:\n",
    "                    for tsta in K:\n",
    "                        sta.append(tsta.code)\n",
    "                        net.append(K.code)\n",
    "                        chan.append(ichan)\n",
    "                        lon.append(tsta.longitude)\n",
    "                        lat.append(tsta.latitude)\n",
    "                        elev.append(tsta.elevation)\n",
    "                        # sometimes one station has many locations and here we only get the first location\n",
    "                        if tsta[0].location_code:\n",
    "                            location.append(tsta[0].location_code)\n",
    "                        else: location.append('*')\n",
    "                        nsta+=1\n",
    "    prepro_para['nsta'] = nsta\n",
    "\n",
    "# rough estimation on memory needs (assume float32 dtype)\n",
    "nsec_chunk = inc_hours/24*86400\n",
    "nseg_chunk = int(np.floor((nsec_chunk-cc_len)/step))+1\n",
    "npts_chunk = int(nseg_chunk*cc_len*samp_freq)\n",
    "memory_size = nsta*npts_chunk*4/1024**3\n",
    "if memory_size > MAX_MEM:\n",
    "    raise ValueError('Require %5.3fG memory but only %5.3fG provided)! Reduce inc_hours to avoid this issue!' % (memory_size,MAX_MEM))\n",
    "\n",
    "\n",
    "########################################################\n",
    "#################DOWNLOAD SECTION#######################\n",
    "########################################################\n",
    "\n",
    "#--------MPI---------\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "if rank==0:\n",
    "    if not os.path.isdir(rootpath):\n",
    "        os.mkdir(rootpath)\n",
    "    if not os.path.isdir(direc):\n",
    "        os.mkdir(direc)\n",
    "    \n",
    "    # output station list\n",
    "    if not down_list:     \n",
    "        dict = {'network':net,\n",
    "                'station':sta,\n",
    "                'channel':chan,\n",
    "                'latitude':lat,\n",
    "                'longitude':lon,\n",
    "                'elevation':elev}\n",
    "        locs = pd.DataFrame(dict)        \n",
    "        locs.to_csv(os.path.join(direc,'station.txt'),index=False)\n",
    "    \n",
    "    # save parameters for future reference\n",
    "    fout = open(metadata,'w')\n",
    "    fout.write(str(prepro_para));fout.close()\n",
    "\n",
    "    # get MPI variables ready \n",
    "    all_chunk = noise_module.get_event_list(start_date[0],end_date[0],inc_hours)\n",
    "    if len(all_chunk)<1:\n",
    "        raise ValueError('Abort! no data chunk between %s and %s' % (start_date[0],end_date[0]))\n",
    "    splits = len(all_chunk)-1\n",
    "else:\n",
    "    splits,all_chunk = [None for _ in range(2)]\n",
    "\n",
    "# broadcast the variables\n",
    "splits = comm.bcast(splits,root=0)\n",
    "all_chunk  = comm.bcast(all_chunk,root=0)\n",
    "extra = splits % size\n",
    "\n",
    "tp = 0\n",
    "# MPI: loop through each time chunk \n",
    "for ick in range(rank,splits,size):\n",
    "\n",
    "    s1=obspy.UTCDateTime(all_chunk[ick])\n",
    "    s2=obspy.UTCDateTime(all_chunk[ick+1]) \n",
    "    date_info = {'starttime':s1,'endtime':s2} \n",
    "    \n",
    "    # keep a track of the channels already exists\n",
    "    num_records = np.zeros(nsta,dtype=np.int16)\n",
    "\n",
    "    # filename of the ASDF file\n",
    "    ff=os.path.join(direc,all_chunk[ick]+'T'+all_chunk[ick+1]+'.h5')\n",
    "    if not os.path.isfile(ff):\n",
    "        with pyasdf.ASDFDataSet(ff,mpi=False,compression=\"gzip-3\",mode='w') as ds:\n",
    "            pass\n",
    "    else:\n",
    "        with pyasdf.ASDFDataSet(ff,mpi=False,mode='r') as rds:\n",
    "            alist = rds.waveforms.list()\n",
    "            for ista in range(nsta):\n",
    "                tname = net[ista]+'.'+sta[ista]\n",
    "                if tname in alist:\n",
    "                    num_records[ista] = len(rds.waveforms[tname].get_waveform_tags())\n",
    "\n",
    "    # appending when file exists\n",
    "    with pyasdf.ASDFDataSet(ff,mpi=False,compression=\"gzip-3\",mode='a') as ds:\n",
    "\n",
    "        # loop through each channel\n",
    "        for ista in range(nsta):\n",
    "\n",
    "            # continue when there are alreay data for sta A at day X\n",
    "            if num_records[ista] == ncomp:\n",
    "                continue\n",
    "\n",
    "            # get inventory for specific station\n",
    "            try:\n",
    "                sta_inv = client.get_stations(network=net[ista],\n",
    "                                              station=sta[ista],\n",
    "                                              location=location[ista],\n",
    "                                              starttime=s1,\n",
    "                                              endtime=s2,\n",
    "                                              level=\"response\")\n",
    "            except Exception as e:\n",
    "                print(e);continue\n",
    "\n",
    "            # add the inventory for all components + all time of this tation         \n",
    "            try:\n",
    "                ds.add_stationxml(sta_inv) \n",
    "            except Exception: \n",
    "                pass   \n",
    "\n",
    "            try:\n",
    "                # get data\n",
    "                t0=time.time()\n",
    "                tr = client.get_waveforms(network=net[ista],\n",
    "                                          station=sta[ista],\n",
    "                                          channel=chan[ista],\n",
    "                                          location=location[ista],\n",
    "                                          starttime=s1,\n",
    "                                          endtime=s2)\n",
    "                t1=time.time()\n",
    "            except Exception as e:\n",
    "                print(e,'for',sta[ista]);continue\n",
    "                \n",
    "            # preprocess to clean data  \n",
    "            print(sta[ista])\n",
    "            tr = noise_module.preprocess_raw(tr,sta_inv,prepro_para,date_info)\n",
    "            t2 = time.time()\n",
    "            tp += t2-t1\n",
    "\n",
    "            if len(tr):\n",
    "                if location[ista] == '*':\n",
    "                    tlocation = str('00')\n",
    "                else:\n",
    "                    tlocation = location[ista]\n",
    "                #new_tags = '{0:s}_{1:s}'.format(chan[ista].lower(),tlocation.lower())\n",
    "                new_tags = chan[ista].lower()\n",
    "                ds.add_waveforms(tr,tag=new_tags)\n",
    "\n",
    "            #if flag:\n",
    "            print(ds,new_tags);print('downloading data %6.2f s; pre-process %6.2f s' % ((t1-t0),(t2-t1)))\n",
    "\n",
    "tt1=time.time()\n",
    "print('downloading step takes %6.2f s with %6.2f for preprocess' %(tt1-tt0, tp))\n",
    "\n",
    "comm.barrier()\n",
    "if rank == 0:\n",
    "    print(\"Download data finished!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ce7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('noisepy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "195f99de8f8694efb8cafeacb7b692c98162b8c90edbc5fc8c52c66a33654e07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
